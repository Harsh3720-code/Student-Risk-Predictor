{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Model Training\n",
    "\n",
    "We will:\n",
    "- Load the preprocessed data\n",
    "- Train a baseline model (Logistic Regression)\n",
    "- Train a more powerful model (Random Forest)\n",
    "- Evaluate and compare their performance"
   ],
   "id": "d24b80b8d9a17429"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T23:05:55.401001Z",
     "start_time": "2026-01-13T23:05:50.234606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression   # simple, interpretable baseline classifier\n",
    "from sklearn.ensemble import RandomForestClassifier   # stronger, nonlinear model\n",
    "# classification_report → precision, recall, F1,\n",
    "# confusion_matrix → error breakdown &\n",
    "# roc_auc_score → overall ranking performance\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ],
   "id": "6c8e34cae78fcf5c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T23:08:54.770514Z",
     "start_time": "2026-01-13T23:08:54.759621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the preprocessed data\n",
    "X_train = np.load(\"../data/preprocessed/X_train.npy\")\n",
    "X_test = np.load(\"../data/preprocessed/X_test.npy\")\n",
    "y_train = np.load(\"../data/preprocessed/y_train.npy\")\n",
    "y_test = np.load(\"../data/preprocessed/y_test.npy\")\n",
    "\n",
    "print(\"Training set shape: \", X_train.shape)\n",
    "print(\"Test set shape: \", X_test.shape)"
   ],
   "id": "4ce13645f8aeeb51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (316, 56)\n",
      "Test set shape:  (79, 56)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Baseline Model: Logistic Regression\n",
    "- It is simple and fast to train\n",
    "- It provides a strong linear baseline for classification\n",
    "- It is easy to interpret\n",
    "- It is commonly used as a reference model in applied machine learning!"
   ],
   "id": "bba656dead936c28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T23:34:16.905070Z",
     "start_time": "2026-01-13T23:34:16.604160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create and train the logistic regression model\n",
    "\n",
    "# max_iter=1000 → ensures convergence\n",
    "# .fit() → trains the model\n",
    "# .predict() → predicted class labels (0/1)\n",
    "# .predict_proba() → predicted probabilities (used for ROC-AUC)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on Test Set\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "y_proba_lr = log_reg.predict_proba(X_test)[:,1]"
   ],
   "id": "c77d5350010f67a2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T23:42:23.471667Z",
     "start_time": "2026-01-13T23:42:23.434942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluation of Logistic Regression\n",
    "\n",
    "# Precision → How many predicted at-risk are actually at-risk\n",
    "# Recall → How many real at-risk students we caught (VERY IMPORTANT)\n",
    "# F1-score → Balance of both\n",
    "# Confusion matrix → Exact error counts\n",
    "# ROC-AUC → Overall ranking quality\n",
    "\n",
    "print(\"Logistic Regression - Classification Report\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "print(\"ROC-AUC Score\", roc_auc_score(y_test, y_pred_lr))"
   ],
   "id": "c79bf45863f7acb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80        53\n",
      "           1       0.57      0.31      0.40        26\n",
      "\n",
      "    accuracy                           0.70        79\n",
      "   macro avg       0.65      0.60      0.60        79\n",
      "weighted avg       0.67      0.70      0.67        79\n",
      "\n",
      "Confusion Matrix\n",
      "[[47  6]\n",
      " [18  8]]\n",
      "ROC-AUC Score 0.5972423802612482\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A better and powerful model: Random Forest\n",
    "Logistic Regression is a linear model. However, student performance may depend on complex, non-linear interactions between variables.\n",
    "\n",
    "Therefore, we also train a Random Forest classifier, which:\n",
    "- Can model non-linear relationships\n",
    "- Is robust to noise\n",
    "- Often performs very well on tabular data.\n"
   ],
   "id": "630db46dd8c53670"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T23:47:15.430272Z",
     "start_time": "2026-01-13T23:47:14.615012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create and train the Random Forest model\n",
    "\n",
    "# n_estimators=200 → number of trees\n",
    "# class_weight=\"balanced\" → helps with class imbalance\n",
    "# Random Forest outputs both:\n",
    "# Class predictions\n",
    "# Probabilities\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42, class_weight=\"balanced\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_proba_rf = rf.predict_proba(X_test)[:,1]"
   ],
   "id": "5aea91b99bb206fa",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T23:48:59.625730Z",
     "start_time": "2026-01-13T23:48:59.574895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluation of Random Forest\n",
    "\n",
    "print(\"Random Forest - Classification Report\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "print(\"ROC-AUC Score\", roc_auc_score(y_test, y_proba_rf))"
   ],
   "id": "1861f87c49b9796c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.92      0.80        53\n",
      "           1       0.56      0.19      0.29        26\n",
      "\n",
      "    accuracy                           0.68        79\n",
      "   macro avg       0.63      0.56      0.54        79\n",
      "weighted avg       0.65      0.68      0.63        79\n",
      "\n",
      "Confusion Matrix\n",
      "[[49  4]\n",
      " [21  5]]\n",
      "ROC-AUC Score 0.6868650217706821\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Therefore, Interpretation:\n",
    "\n",
    "1. Logistic Regression:\n",
    "\n",
    "- Is very good at identifying safe students\n",
    "- Is bad at catching at-risk students (Out of 26 it only caught 8 students at risk - Not so GREAT!)\n",
    "- ROC-AUC ≈ 0.60 → only slightly better than random\n",
    "\n",
    "2. Random Forest:\n",
    "\n",
    "- Has better ROC-AUC (0.687 vs 0.597) → better ranking\n",
    "But:\n",
    "- With default threshold, it is even worse at catching at-risk students (catched only 5 students at risk out of 21)\n",
    "- It is extremely conservative.\n",
    "\n",
    "Hence,\n",
    "\n",
    "**Logistic Regression** is currently better because it catches more at-risk students\n",
    "Even though **Random Forest** is better at ranking, it is: Too conservative at the default threshold."
   ],
   "id": "3365717d9084eeb9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
