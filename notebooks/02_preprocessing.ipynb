{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Data Preprocessing\n",
    "\n",
    "This notebook prepares the dataset for machine learning by:\n",
    "- Separating features and target\n",
    "- Encoding categorical variables\n",
    "- Scaling numerical variables\n",
    "- Splitting the data into training and test sets."
   ],
   "id": "69ea72b72e73a11c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T21:13:08.464305Z",
     "start_time": "2026-01-13T21:13:08.408076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/raw/student-mat.csv\", sep=\";\")\n",
    "\n",
    "#Recreate the target variable\n",
    "df['at_risk'] = (df['G3'] < 10).astype(int)\n",
    "df.head()\n"
   ],
   "id": "eeebc12763dc1bfa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  freetime goout  Dalc  Walc  health absences  G1  G2  G3 at_risk  \n",
       "0        3     4     1     1       3        6   5   6   6       1  \n",
       "1        3     3     1     1       3        4   5   5   6       1  \n",
       "2        3     2     2     3       3       10   7   8  10       0  \n",
       "3        2     2     1     1       5        2  15  14  15       0  \n",
       "4        3     2     1     2       5        4   6  10  10       0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "      <th>at_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Removing Leakage-Prone Columns\n",
    "The column G3 is the final grade & was used to create the target variable 'at_risk'. Therefore, it must be removed from the inout features to avoid the **data leakage**."
   ],
   "id": "646505a05985797f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T21:48:46.808757Z",
     "start_time": "2026-01-13T21:48:46.673178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop columns that would cause data to leak\n",
    "df_model = df.drop(columns=['G3','G1','G2'])"
   ],
   "id": "f7f5ca633e11fd1e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T21:53:10.561455Z",
     "start_time": "2026-01-13T21:53:10.518897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Separating  features and target\n",
    "# We separate: 'X': Input Features & 'Y': Target Variable ('at_risk')\n",
    "x = df_model.drop(columns=['at_risk'])\n",
    "y = df_model['at_risk']\n",
    "\n",
    "print(\"X Shape:\", x.shape)\n",
    "print(\"Y Shape:\", y.shape)\n"
   ],
   "id": "19634916cebed874",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape: (395, 30)\n",
      "Y Shape: (395,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T22:15:11.141898Z",
     "start_time": "2026-01-13T22:15:11.059601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Identifying categorical & numerical columns\n",
    "categorical_cols = x.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = x.select_dtypes(exclude='object').columns.tolist()\n",
    "\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "print(\"Numerical columns:\", numerical_cols)"
   ],
   "id": "283f2ce9ff512461",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']\n",
      "Numerical columns: ['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T22:15:33.514161Z",
     "start_time": "2026-01-13T22:15:33.494872Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(categorical_cols), len(numerical_cols))",
   "id": "5ce26548967fd6be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 13\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Identifying Feature Types\n",
    "\n",
    "The dataset contains a mixture of categorical and numerical features.\n",
    "\n",
    "- **Categorical features (17 columns):**\n",
    "  - These represent qualitative attributes such as gender, school, parental job, and support indicators.\n",
    "  - These features must be converted into numerical form using one-hot encoding.\n",
    "\n",
    "- **Numerical features (13 columns):**\n",
    "  - These represent quantitative measurements such as age, number of absences, and study time.\n",
    "  - These features will be scaled to ensure they are on a comparable numerical scale.\n",
    "\n",
    "In total, the feature set contains 30 input variables."
   ],
   "id": "121b5c9468a022c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **Numerical features**:\n",
    "  - Will be scaled using `StandardScaler` so that they have zero mean and unit variance.\n",
    "- **Categorical features**:\n",
    "  - Will be converted into numerical form using **One-Hot Encoding**.\n",
    "\n",
    "To ensure clean, reproducible, and leakage-free preprocessing, we will use:\n",
    "- `ColumnTransformer` to apply different transformations to different columns.\n",
    "- `Pipeline` to chain preprocessing steps together."
   ],
   "id": "29eab334193655c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T22:24:41.237913Z",
     "start_time": "2026-01-13T22:24:39.150303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import Preprocessing Tools\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # splits data into training and test sets\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder   # Scales numeric features & the other converts categories into numeric vectors\n",
    "from sklearn.compose import ColumnTransformer   # applies different transformations to different columns\n",
    "from sklearn.pipeline import Pipeline   # chains steps together safely\n"
   ],
   "id": "e12407178f1e068c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Defining Feature Transformers\n",
    "\n",
    "- A numerical transformer that scales numerical features.\n",
    "- A categorical transformer that one-hot encodes categorical features."
   ],
   "id": "eb8f0e861bccaef7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T22:30:59.658096Z",
     "start_time": "2026-01-13T22:30:59.652955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transformer for numerical feature (Pipeline creates a sequence of transformations)\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "# Transformer for categorical features (OneHotEncoder converts categories to numbers & avoids crashing if unseen categories appear in test data.)\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ],
   "id": "668e85f394055be0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Combining Transformers Using **ColumnTransformer**\n",
    "\n",
    "Combining the numerical and categorical transformers into a single preprocessing object.\n"
   ],
   "id": "92b1988fdd11be1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T22:37:19.679144Z",
     "start_time": "2026-01-13T22:37:19.667097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine preprocessing for numerical & categorical features\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numerical_cols), ('cat', categorical_transformer, categorical_cols)])"
   ],
   "id": "8fd960b85becf02a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Splitting the dataset:\n",
    "- Training set: (80%)\n",
    "- Testing set: (20%)\n"
   ],
   "id": "80d5b57b848d4a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T22:44:57.980792Z",
     "start_time": "2026-01-13T22:44:57.730444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)   # test_size=20% for testing, random_state=42 for reproducible split & stratify=y as it preserves the class balance in both splits\n",
    "\n",
    "print(\"Training set shape: \", X_train.shape)\n",
    "print(\"Test set shape: \", X_test.shape)"
   ],
   "id": "82959ddf29542b50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (316, 30)\n",
      "Test set shape:  (79, 30)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Applying the Preprocessing Pipeline\n",
    "\n",
    "- Fit the preprocessing pipeline on the training data\n",
    "- Transform both training and testing data"
   ],
   "id": "ff11db4a86f4a4d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T22:50:45.098225Z",
     "start_time": "2026-01-13T22:50:45.039904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit preprocessor on training data and transform both sets\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Processed training shape: \", X_train_processed.shape)\n",
    "print(\"Processed test shape: \", X_test_processed.shape)"
   ],
   "id": "72a698f0cb7dcff2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed training shape:  (316, 56)\n",
      "Processed test shape:  (79, 56)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Saving the Processed Data\n",
    "\n",
    "Saving the processed datasets so they can be reused for model training and evaluation.\n"
   ],
   "id": "bbb0232060b63a77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-13T22:55:43.906589Z",
     "start_time": "2026-01-13T22:55:43.882111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save(\"../data/preprocessed/X_train.npy\", X_train_processed)\n",
    "np.save(\"../data/preprocessed/X_test.npy\", X_test_processed)\n",
    "np.save(\"../data/preprocessed/y_train.npy\", y_train.values)     # .values converts pandas Series → NumPy array\n",
    "np.save(\"../data/preprocessed/y_test.npy\", y_test.values)       # .values converts pandas Series → NumPy array\n"
   ],
   "id": "7eba3e7513dfe66a",
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
